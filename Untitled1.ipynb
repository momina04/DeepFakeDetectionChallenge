{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer.audio_trainer import AudioTrainer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--load_model_only'], dest='load_model_only', nargs=0, const=True, default=False, type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from argparse import ArgumentParser, Namespace\n",
    "parser = ArgumentParser(parents=[])\n",
    "parser.add_argument('--sequence_length', default=200, type=int)\n",
    "parser.add_argument('--num_sequences', default=1, type=int)\n",
    "parser.add_argument('--batch_size', default=64, type=int)\n",
    "parser.add_argument('--num_workers', default=0, type=int)\n",
    "\n",
    "parser.add_argument('--network_name', type=str)\n",
    "parser.add_argument('--epochs', default=3, type=int)\n",
    "parser.add_argument('--save_dir', default=None, type=str)\n",
    "parser.add_argument('--checkpoint_dir', default=None, type=str)\n",
    "\n",
    "parser.add_argument('--grad_acc_num', default=1, type=int)\n",
    "parser.add_argument('--lr', type=float, default=0.0003) \n",
    "\n",
    "parser.add_argument('--train_dir', type=str)\n",
    "parser.add_argument('--train_meta_file', type=str)\n",
    "parser.add_argument('--valid_dir', type=str)\n",
    "parser.add_argument('--valid_meta_file', type=str)\n",
    "\n",
    "parser.add_argument('--project_name', default=None, type=str)\n",
    "parser.add_argument('--run_name', default=None, type=str)\n",
    "\n",
    "parser.add_argument('--optimizer_name', type=str)\n",
    "parser.add_argument('--scheduler_name', type=str)\n",
    "parser.add_argument('--criterion_name', type=str)\n",
    "parser.add_argument('--tuning_type', type=str)\n",
    "parser.add_argument('--device', type=str, default='cuda')\n",
    "\n",
    "parser.add_argument('--use_amp', dest='use_amp', action='store_true')\n",
    "parser.add_argument('--load_model_only', dest='load_model_only', action='store_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = parser.parse_known_args()[0]\n",
    "\n",
    "hyperparams.sequence_length = 200\n",
    "hyperparams.num_sequences = 1\n",
    "hyperparams.batch_size = 32\n",
    "hyperparams.num_workers = 0\n",
    "\n",
    "hyperparams.network_name = 'efficientnet-b0'\n",
    "hyperparams.epochs = 5\n",
    "hyperparams.save_dir = \"test_saving/save2\"\n",
    "hyperparams.checkpoint_dir = None # \"test_saving/save-49\" # \"test_saving/save-16\" # \"test_saving/save_name3-50\"\n",
    "hyperparams.grad_acc_num = 1\n",
    "hyperparams.lr = 1e-4\n",
    "\n",
    "hyperparams.train_dir = \"../dltraining/wavs\"\n",
    "hyperparams.train_meta_file = \"train_audio_meta.json\"\n",
    "\n",
    "hyperparams.valid_dir = \"../dltraining/wavs\"\n",
    "hyperparams.valid_meta_file = \"valid_audio_meta.json\"\n",
    "\n",
    "hyperparams.project_name = None #'deep-fake-challenge-v2'\n",
    "hyperparams.run_name = None # \"kztqh1r0\" # \"41sw5t9s\"\n",
    "\n",
    "hyperparams.optimizer_name = None\n",
    "hyperparams.scheduler_name = None # \"warmup-with-reduce\" # \"warmup-with-cosine\"\n",
    "hyperparams.criterion_name = None\n",
    "hyperparams.tuning_type = None\n",
    "hyperparams.use_amp = False\n",
    "hyperparams.device = \"cpu\"\n",
    "hyperparams.load_model_only = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "trainer = AudioTrainer(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f6c034fd73477cbb04a521d704f73b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=253), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/librosa/filters.py:235: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1005])\n",
      "torch.Size([128, 1005])\n",
      "torch.Size([128, 1001])\n",
      "torch.Size([128, 1005])\n",
      "torch.Size([128, 1001])\n",
      "torch.Size([128, 1001])\n",
      "torch.Size([128, 1001])\n",
      "torch.Size([128, 1001])\n",
      "torch.Size([128, 1001])\n",
      "torch.Size([128, 1001])\n",
      "torch.Size([128, 1005])\n",
      "torch.Size([128, 1001])\n",
      "torch.Size([128, 1001])\n",
      "torch.Size([128, 1001])\n",
      "torch.Size([128, 1005])\n",
      "torch.Size([128, 1005])\n",
      "torch.Size([128, 1001])\n",
      "torch.Size([128, 1005])\n",
      "torch.Size([128, 1001])\n",
      "torch.Size([128, 1001])\n",
      "torch.Size([128, 1001])\n",
      "torch.Size([128, 1001])\n",
      "torch.Size([128, 1001])\n",
      "torch.Size([128, 1001])\n",
      "torch.Size([128, 1001])\n",
      "torch.Size([128, 1005])\n",
      "torch.Size([128, 1001])\n",
      "torch.Size([128, 1001])\n",
      "torch.Size([128, 1001])\n",
      "torch.Size([128, 1005])\n",
      "torch.Size([128, 1005])\n",
      "torch.Size([128, 1001])\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train_on_sample(50, log_every=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
